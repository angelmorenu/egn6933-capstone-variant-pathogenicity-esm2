{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7125e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/clinvar/variant_summary.txt.gz')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = Path('data/clinvar/variant_summary.txt.gz')\n",
    "ALT_PATH = Path('../Project/data/clinvar/variant_summary.txt.gz')\n",
    "\n",
    "if not DATA_PATH.exists() and ALT_PATH.exists():\n",
    "    print('Using course workspace ClinVar file:', ALT_PATH)\n",
    "    DATA_PATH = ALT_PATH\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2757b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Neither data/clinvar/variant_summary.txt.gz nor ../Project/data/clinvar/variant_summary.txt.gz exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \tdf_sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(ALT_PATH, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50_000\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m df_sample\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Neither data/clinvar/variant_summary.txt.gz nor ../Project/data/clinvar/variant_summary.txt.gz exists."
     ]
    }
   ],
   "source": [
    "# Read a small sample first (fast sanity check)\n",
    "if DATA_PATH.exists():\n",
    "\tdf_sample = pd.read_csv(DATA_PATH, sep='\\t', compression='gzip', nrows=50_000, low_memory=False)\n",
    "elif ALT_PATH.exists():\n",
    "\tprint('Using alternate path:', ALT_PATH)\n",
    "\tdf_sample = pd.read_csv(ALT_PATH, sep='\\t', compression='gzip', nrows=50_000, low_memory=False)\n",
    "else:\n",
    "\traise FileNotFoundError(f\"Neither {DATA_PATH} nor {ALT_PATH} exists.\")\n",
    "\n",
    "df_sample.shape  # (50000, 86)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.columns.tolist()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key fields we care about\n",
    "cols = [\n",
    "    'ClinicalSignificance', 'ReviewStatus', 'ClinSigSimple',\n",
    "    'Assembly', 'Chromosome', 'PositionVCF', 'ReferenceAlleleVCF', 'AlternateAlleleVCF',\n",
    "    'Start', 'Stop', 'ReferenceAllele', 'AlternateAllele',\n",
    "]\n",
    "[c for c in cols if c in df_sample.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40497fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly distribution (sample)\n",
    "if 'Assembly' in df_sample.columns:\n",
    "    display(df_sample['Assembly'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical significance (sample)\n",
    "if 'ClinicalSignificance' in df_sample.columns:\n",
    "    display(df_sample['ClinicalSignificance'].value_counts(dropna=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromosome distribution (sample)\n",
    "if 'Chromosome' in df_sample.columns:\n",
    "    display(df_sample['Chromosome'].astype(str).str.replace('chr', '', regex=False).value_counts().head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ce92d",
   "metadata": {},
   "source": [
    "## Next steps (after this notebook)\n",
    "\n",
    "1. Define *high-confidence* label mapping rules for your curated dataset.\n",
    "2. Decide the assembly for v1 (default: GRCh38).\n",
    "3. Create a curated Parquet with a binary `label` column and a single assembly.\n",
    "4. Run VEP on a pilot set to define the non-coding subset.\n",
    "5. Use `scripts/make_splits.py` to generate chromosome holdout splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
