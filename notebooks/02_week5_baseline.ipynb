{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6558cce",
   "metadata": {},
   "source": [
    "## Dataset conventions \n",
    "\n",
    "- Canonical variant key: `chr_pos_ref_alt` (e.g., `17_43045705_T_C`) derived from `chrom`, `pos`, `ref`, `alt`.\n",
    "- Variants are **missense SNVs** (single-nucleotide variants).\n",
    "- Labels: strict ClinVar clinical significance mapping (B/LB → 0, P/LP → 1); ambiguous categories excluded or handled upstream in the cleaned table.\n",
    "- Leakage control: **gene-disjoint** train/val/test splits (implemented in `scripts/make_week3_splits.py`).\n",
    "\n",
    "See also: `docs/dataset_orientation_dylan_tan.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441b45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/angelhdmorenu/Desktop/EGN 6933 – Project in Applied Data Science/Machine Learning Classification of Pathogenic vs. Benign Missense Variants Using Protein Language Model Embeddings\n",
      "Week4 curated dataset exists: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == 'notebooks' else Path.cwd().resolve()\n",
    "DATA_PATH = REPO_ROOT / 'data/processed/week4_curated_dataset.parquet'\n",
    "\n",
    "print('Repo root:', REPO_ROOT)\n",
    "print('Week4 curated dataset exists:', DATA_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee99beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5000\n",
      "Splits: Counter({'train': 3958, 'val': 542, 'test': 500})\n",
      "Label balance overall: {0: 3161, 1: 1839}\n",
      "Label balance by split:\n",
      "label     0     1\n",
      "split            \n",
      "test    316   184\n",
      "train  2499  1459\n",
      "val     346   196\n",
      "Embedding dim (first row): 2560\n",
      "Rows with mismatched embedding length: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    print('Missing curated dataset:', DATA_PATH)\n",
    "    print('Generate it via: python scripts/make_week4_curated_dataset.py')\n",
    "else:\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    required = {'chr_pos_ref_alt', 'label', 'split', 'embedding'}\n",
    "    missing = sorted(required - set(df.columns))\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing required columns in curated dataset: {missing}')\n",
    "\n",
    "    print('Rows:', len(df))\n",
    "    print('Splits:', Counter(df['split']))\n",
    "    print('Label balance overall:', df['label'].value_counts().to_dict())\n",
    "    print('Label balance by split:')\n",
    "    print(df.groupby('split')['label'].value_counts().unstack(fill_value=0))\n",
    "\n",
    "    # quick embedding sanity-check\n",
    "    first_len = len(df['embedding'].iloc[0])\n",
    "    print('Embedding dim (first row):', first_len)\n",
    "    bad_dim = (df['embedding'].map(len) != first_len).sum()\n",
    "    print('Rows with mismatched embedding length:', int(bad_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15b6aa",
   "metadata": {},
   "source": [
    "## Week 5 baseline run commands\n",
    "\n",
    "The main entrypoint for baselines is `scripts/baseline_train_eval.py`.\n",
    "\n",
    "Run Logistic Regression baseline:\n",
    "\n",
    "```bash\n",
    "python scripts/baseline_train_eval.py \\\n",
    "  --data data/processed/week4_curated_dataset.parquet \\\n",
    "  --out-json results/baseline_logreg_report.json\n",
    "```\n",
    "\n",
    "Run Random Forest baseline + calibration + bootstrap CIs + plots:\n",
    "\n",
    "```bash\n",
    "python scripts/baseline_train_eval.py \\\n",
    "  --model rf \\\n",
    "  --rf-max-depth 4 \\\n",
    "  --rf-n-estimators 200 \\\n",
    "  --data data/processed/week4_curated_dataset.parquet \\\n",
    "  --calibration platt \\\n",
    "  --bootstrap-iters 1000 \\\n",
    "  --plot-pr results/rf_pr_curves_cal_vs_uncal.png \\\n",
    "  --plot-reliability results/rf_reliability.png \\\n",
    "  --plot-scores-test results/test_score_distributions.png \\\n",
    "  --out-json results/baseline_rf_calibrated_report.json\n",
    "```\n",
    "\n",
    "If you are needing to split-seed robustness (gene-disjoint), regenerate splits with a different `--seed` using `scripts/make_week3_splits.py`, rebuild Week 4, then rerun baselines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
